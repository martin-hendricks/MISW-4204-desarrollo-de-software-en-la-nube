# Producer - Pruebas de Carga para Worker

Este script permite realizar pruebas de carga enviando tareas de procesamiento de video a la cola de AWS SQS (o Redis en modo desarrollo).

## Requisitos Previos

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2. Configurar Variables de Entorno

Copia el archivo de ejemplo y config칰ralo con tus valores:

```bash
cp .env.example .env
```

Edita el archivo `.env` con los valores correctos:

#### Para AWS SQS + S3 (Producci칩n en la Nube)

```bash
# Broker: AWS SQS
USE_SQS=true
AWS_REGION=us-east-1
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-queue
SQS_DLQ_URL=https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-dlq

# Storage: AWS S3
USE_S3=true
S3_BUCKET_NAME=your-bucket-name

# Credenciales de AWS (solo si no usas IAM Role)
AWS_ACCESS_KEY_ID=tu_access_key
AWS_SECRET_ACCESS_KEY=tu_secret_key
AWS_SESSION_TOKEN=tu_session_token
```

#### Para Redis + Volumen Local (Desarrollo Local)

```bash
# Broker: Redis
USE_SQS=false
REDIS_URL=redis://localhost:6379/0

# Storage: Volumen compartido local
USE_S3=false
```

### 3. Configurar AWS SQS

Si a칰n no has creado las colas de SQS, ejecuta:

```bash
cd ../../deployment/sqs-setup
./setup-sqs.sh us-east-1
```

Esto generar치 un archivo `sqs-config.env` con las URLs necesarias.

### 4. Configurar AWS S3

Si est치s usando S3 para almacenamiento (`USE_S3=true`), necesitas:

#### Opci칩n 1: Crear bucket manualmente

```bash
# Crear bucket
aws s3 mb s3://your-bucket-name --region us-east-1

# Crear estructura de carpetas
aws s3api put-object --bucket your-bucket-name --key original/ --content-length 0
aws s3api put-object --bucket your-bucket-name --key processed/ --content-length 0
```

#### Opci칩n 2: Usar el script de setup del backend

```bash
cd ../../deployment/backend-instance
# Edita el archivo .env con S3_BUCKET_NAME
./setup-s3.sh
```

#### Verificar que el bucket existe

```bash
# Listar buckets
aws s3 ls

# Verificar contenido del bucket
aws s3 ls s3://your-bucket-name/
```

## Uso del Producer

### Sintaxis B치sica

```bash
python producer.py [opciones]
```

### Opciones Disponibles

| Opci칩n | Descripci칩n | Valor por defecto |
|--------|-------------|-------------------|
| `--num-videos` | N칰mero de videos a procesar | 10 |
| `--video-file` | Ruta al archivo de video de prueba | `./assets/dummy_file_50mb.mp4` |
| `--timeout` | Tiempo m치ximo de espera en segundos | 600 (10 minutos) |
| `--debug` | Activar modo debug con informaci칩n adicional | Desactivado |
| `--no-wait` | Solo encolar tareas sin esperar resultados | Desactivado |

### Ejemplos de Uso

#### 1. Prueba b치sica con 10 videos

```bash
python producer.py
```

#### 2. Prueba de carga con 100 videos

```bash
python producer.py --num-videos 100
```

#### 3. Prueba con video personalizado

```bash
python producer.py --num-videos 50 --video-file /ruta/a/tu/video.mp4
```

#### 4. Prueba con timeout personalizado (30 minutos)

```bash
python producer.py --num-videos 200 --timeout 1800
```

#### 5. Solo encolar tareas sin esperar (recomendado para pruebas grandes)

```bash
python producer.py --num-videos 1000 --no-wait
```

#### 6. Modo debug para troubleshooting

```bash
python producer.py --num-videos 5 --debug
```

## C칩mo Funciona

### Con AWS SQS + S3 (Producci칩n en la Nube)

1. **Validaci칩n**:
   - Verifica la conexi칩n a AWS SQS y las credenciales
   - Verifica que el bucket de S3 existe y es accesible
2. **Preparaci칩n**:
   - Sube los archivos de video a S3 en la carpeta `original/`
   - Cada archivo se nombra con el ID de la tarea (ej: `1.mp4`, `2.mp4`, etc.)
3. **Encolado**:
   - Env칤a las tareas a la cola de SQS `video_processing`
   - Cada tarea contiene el `video_id` que el worker usar치 para descargar el archivo de S3
4. **Monitoreo**:
   - Si `--no-wait`: Termina inmediatamente despu칠s de encolar
   - Si espera resultados: Monitorea la cola de SQS para ver cu치ntos mensajes quedan

### Con Redis + Volumen Local (Desarrollo Local)

1. **Validaci칩n**: Verifica que Redis est칠 disponible y la carpeta local existe
2. **Preparaci칩n**: Copia los archivos de video al volumen compartido local
3. **Encolado**: Env칤a las tareas a la cola de Redis
4. **Monitoreo**: Puede rastrear el progreso de las tareas si el result backend est치 configurado

## Monitoreo del Procesamiento

### Opci칩n 1: Logs del Worker

```bash
# Si el worker est치 en Docker
docker logs -f <worker-container-name>

# Si el worker est치 en EC2
ssh ec2-user@WORKER_IP
sudo journalctl -u worker -f
```

### Opci칩n 2: AWS SQS Console

1. Ve a la [Consola de AWS SQS](https://console.aws.amazon.com/sqs/)
2. Selecciona la cola `anb-video-processing-queue`
3. Monitorea las m칠tricas:
   - Mensajes disponibles
   - Mensajes en vuelo
   - Edad del mensaje m치s antiguo

### Opci칩n 3: CloudWatch Metrics

El worker env칤a m칠tricas autom치ticamente a CloudWatch:

```bash
# Ver m칠tricas de TaskCount
aws cloudwatch get-metric-statistics \
  --namespace ANB/Worker \
  --metric-name TaskCount \
  --dimensions Name=Status,Value=Success \
  --start-time 2025-01-01T00:00:00Z \
  --end-time 2025-01-01T23:59:59Z \
  --period 300 \
  --statistics Sum

# Ver m칠tricas de TaskDuration
aws cloudwatch get-metric-statistics \
  --namespace ANB/Worker \
  --metric-name TaskDuration \
  --start-time 2025-01-01T00:00:00Z \
  --end-time 2025-01-01T23:59:59Z \
  --period 300 \
  --statistics Average,Maximum,Minimum
```

## Salida del Producer

### Informaci칩n de Inicio

```
============================================================
游 Iniciando prueba de rendimiento del Worker
   - Tareas a generar: 100
   - Archivo de video: ./assets/dummy_file_50mb.mp4
   - Destino de worker: /app/uploads/original
   - Timeout: 600 segundos
   - Broker: AWS SQS
   - AWS Region: us-east-1
   - SQS Queue: anb-video-processing-queue
   - Modo Debug: Desactivado
   - Modo: Encolar y esperar resultados
============================================================
```

### Durante el Procesamiento (con SQS)

```
[Paso 3/4] Esperando resultados...
   Timeout configurado: 600 segundos

   Monitoreando la cola de SQS...
   Mensajes en cola: 45 | En procesamiento: 5 | Tiempo: 120.5s
```

### Resultados Finales

```
============================================================
游늵 Resultados de la Prueba de Rendimiento
------------------------------------------------------------
   - Videos procesados:       100
   - Tama침o por video:        50.00 MB
   - Datos totales:           5000.00 MB
   - Tiempo total:            245.67 segundos
   - Throughput (videos/seg): 0.41
   - Throughput (videos/min): 24.44
============================================================
```

## Troubleshooting

### Error: "No se encontraron credenciales de AWS"

**Soluci칩n**: Configura las credenciales de AWS en el archivo `.env` o usa un IAM Role si est치s en EC2.

```bash
# Opci칩n 1: Variables de entorno
export AWS_ACCESS_KEY_ID=tu_access_key
export AWS_SECRET_ACCESS_KEY=tu_secret_key
export AWS_SESSION_TOKEN=tu_session_token

# Opci칩n 2: Configurar AWS CLI
aws configure
```

### Error: "La cola SQS no existe"

**Soluci칩n**: Crea las colas ejecutando el script de setup:

```bash
cd ../../deployment/sqs-setup
./setup-sqs.sh us-east-1
```

### Error: "El bucket S3 no existe" o "No tienes permisos para acceder al bucket"

**Soluci칩n**: Verifica que el bucket existe y tienes los permisos correctos:

```bash
# Listar buckets
aws s3 ls

# Crear bucket si no existe
aws s3 mb s3://your-bucket-name --region us-east-1

# Verificar permisos de tu usuario IAM
aws s3 ls s3://your-bucket-name/
```

Si est치s usando AWS Academy, aseg칰rate de:
1. Tener las credenciales actualizadas (expiran cada 4 horas)
2. Incluir el `AWS_SESSION_TOKEN` en el archivo `.env`

### Error: "Error al subir archivo a S3"

**Causas comunes**:
1. **Credenciales expiradas**: Actualiza las credenciales de AWS Academy
2. **Permisos insuficientes**: Verifica que tu usuario IAM tiene permisos `s3:PutObject`
3. **Bucket en otra regi칩n**: Verifica que `AWS_REGION` coincide con la regi칩n del bucket

**Verificaci칩n**:
```bash
# Probar subida manual
echo "test" > test.txt
aws s3 cp test.txt s3://your-bucket-name/original/test.txt

# Verificar que se subi칩
aws s3 ls s3://your-bucket-name/original/
```

### Error: "No se puede continuar sin la carpeta de uploads" (Modo Local)

**Soluci칩n**: Aseg칰rate de que el volumen compartido est칠 montado correctamente o que la carpeta exista:

```bash
mkdir -p /app/uploads/original
```

### Las tareas se encolan pero nunca se procesan

**Verificar**:
1. El worker est치 corriendo: `docker ps | grep worker`
2. El worker tiene las mismas credenciales de AWS
3. El worker tiene `USE_SQS=true` configurado
4. Las URLs de SQS coinciden entre producer y worker

## Notas Importantes

### AWS SQS

1. **L칤mites de SQS**: AWS SQS tiene l칤mites de throughput. Para pruebas muy grandes (>1000 tareas), considera usar `--no-wait` y monitorear desde CloudWatch.

2. **Costos de SQS**: Cada llamada a SQS tiene un costo. El long polling (configurado a 20 segundos) ayuda a reducir costos.

3. **Timeout de Visibilidad**: Las tareas tienen 1 hora (3600 segundos) de visibility timeout. Si un worker no completa la tarea en ese tiempo, la tarea volver치 a la cola.

4. **Dead Letter Queue**: Despu칠s de 3 reintentos fallidos, las tareas se mueven autom치ticamente a la DLQ para su an치lisis.

### AWS S3

5. **Costos de S3**: Cada operaci칩n de S3 (PUT, GET, LIST) tiene un costo. Subir 1000 videos generar치:
   - 1000 operaciones PUT (subida del producer)
   - 1000 operaciones GET (descarga del worker)
   - 1000 operaciones PUT (subida del video procesado)
   - Costo de almacenamiento por GB-mes

6. **Credenciales de AWS Academy**: Las credenciales expiran cada 4 horas. Si tienes un error de credenciales durante una prueba larga:
   - Actualiza las credenciales en el archivo `.env`
   - Exporta las variables: `export $(grep -v '^#' .env | xargs)`

7. **Nombres 칰nicos de archivos**: El producer usa IDs secuenciales (1.mp4, 2.mp4, etc.). Si ejecutas el producer m칰ltiples veces, sobrescribir치 archivos anteriores en S3.

8. **Regi칩n de S3**: Aseg칰rate de que el bucket de S3 y las colas de SQS est칠n en la misma regi칩n AWS para reducir costos y latencia.

### Monitoreo

9. **CloudWatch Integration**: El worker env칤a m칠tricas autom치ticamente. Revisa CloudWatch para an치lisis detallado del rendimiento.

10. **Modo `--no-wait`**: Recomendado para pruebas de carga grandes. El producer terminar치 inmediatamente despu칠s de subir los archivos y encolar las tareas, permiti칠ndote monitorear desde CloudWatch o los logs del worker.
