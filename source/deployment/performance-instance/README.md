# Performance Testing Instance - Deployment (AWS SQS + S3)

Esta carpeta contiene los archivos necesarios para desplegar una instancia de **Performance Testing** en AWS EC2 que ejecuta pruebas de carga contra tu infraestructura de procesamiento de videos usando **AWS SQS** y **S3**.

## üÜï Actualizaci√≥n: Migraci√≥n a AWS SQS y S3

Esta configuraci√≥n ahora usa:
- **AWS SQS** como broker de mensajes (en lugar de Redis con SSH tunnel)
- **AWS S3** para almacenamiento de videos (en lugar de vol√∫menes locales/NFS)

### ¬øPor qu√© migrar a SQS y S3?

‚úÖ **Escalabilidad**: SQS y S3 escalan autom√°ticamente sin configuraci√≥n adicional
‚úÖ **Confiabilidad**: Servicios administrados por AWS con alta disponibilidad
‚úÖ **Simplicidad**: No requiere t√∫neles SSH ni sincronizaci√≥n de archivos
‚úÖ **Costo-efectivo**: Pago por uso, sin infraestructura permanente
‚úÖ **AWS Academy compatible**: Funciona perfectamente con credenciales temporales

## üìÅ Archivos en esta carpeta

- **[DEPLOY.md](./DEPLOY.md)** - Gu√≠a completa paso a paso para el deployment
- **docker-compose.yml** - Configuraci√≥n de Docker Compose (con soporte SQS/S3)
- **prometheus.yml** - Configuraci√≥n de Prometheus para scraping de m√©tricas
- **setup-ssh-tunnel.sh** - Script de configuraci√≥n (ahora configura Prometheus)
- **.env.example** - Plantilla de variables de entorno (actualizada para SQS/S3)

## üöÄ Inicio R√°pido

### 1. Lee la gu√≠a completa de deployment

‚û°Ô∏è **[DEPLOY.md](./DEPLOY.md)**

Esta gu√≠a contiene TODOS los pasos necesarios, incluyendo:

- Creaci√≥n de la instancia EC2
- Configuraci√≥n de Security Groups
- Instalaci√≥n de Docker
- Configuraci√≥n de AWS SQS y S3
- Deployment de servicios (Prometheus, Grafana, JMeter, Producer)
- Ejecuci√≥n de pruebas de carga
- Troubleshooting

### 2. Requisitos previos

Antes de comenzar, aseg√∫rate de tener:

- [ ] Una cuenta de AWS Academy o AWS con permisos para:
  - Crear instancias EC2
  - Crear colas SQS
  - Crear buckets S3
- [ ] Credenciales de AWS (Access Key, Secret Key, Session Token)
- [ ] IP p√∫blica del backend (para JMeter y m√©tricas de Prometheus)
- [ ] Worker configurado para usar SQS y S3

### 3. Configuraci√≥n AWS necesaria

Necesitar√°s configurar:

```bash
# AWS SQS
SQS_QUEUE_URL: https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-queue
SQS_DLQ_URL: https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-dlq

# AWS S3
S3_BUCKET_NAME: your-bucket-name

# AWS Credentials (desde AWS Academy)
AWS_ACCESS_KEY_ID: ASIA...
AWS_SECRET_ACCESS_KEY: ...
AWS_SESSION_TOKEN: ...

# Backend/Worker IPs (para Prometheus)
PROMETHEUS_BACKEND_TARGET: 3.XXX.XXX.XXX:8000
PROMETHEUS_WORKER_TARGET: 3.YYY.YYY.YYY:8001
```

## üéØ ¬øQu√© hace esta instancia?

La instancia de Performance Testing ejecuta:

1. **Producer** (Python + Celery Client)
   - Inyecta tareas en AWS SQS
   - Sube videos de prueba a S3
   - Simula carga de procesamiento de videos
   - Soporta monitoreo de progreso con CloudWatch

2. **JMeter**
   - Ejecuta pruebas de carga HTTP contra la API del backend
   - Soporta smoke tests, ramp-up tests y sustained tests
   - Genera reportes de rendimiento

3. **Prometheus**
   - Recolecta m√©tricas del backend y worker remotos v√≠a HTTP
   - Almacena datos de rendimiento
   - Expone m√©tricas en puerto 9090

4. **Grafana**
   - Visualiza m√©tricas en dashboards interactivos
   - Accesible en puerto 3000
   - Dashboards pre-configurados para API y Worker

## üìä Arquitectura (AWS SQS + S3)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TU CUENTA AWS                                           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ EC2: Performance Testing                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Producer (env√≠a mensajes a SQS)               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ JMeter (pruebas HTTP)                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Prometheus (recolecta m√©tricas)               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Grafana (visualizaci√≥n)                       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ            ‚îÇ                   ‚îÇ                        ‚îÇ
‚îÇ            ‚îÇ                   ‚îÇ                        ‚îÇ
‚îÇ            ‚ñº                   ‚ñº                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ  AWS SQS         ‚îÇ  ‚îÇ  AWS S3         ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Main Queue    ‚îÇ  ‚îÇ  ‚Ä¢ Videos       ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DLQ           ‚îÇ  ‚îÇ    (original/)  ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ            ‚îÇ                   ‚îÇ                        ‚îÇ
‚îÇ            ‚îÇ                   ‚îÇ                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                   ‚îÇ
             ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TU INFRAESTRUCTURA DE BACKEND/WORKER                   ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ EC2: Backend                 ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ API (HTTP) ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ JMeter   ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ M√©tricas :8000            ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ EC2: Worker(s)               ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Lee mensajes de SQS       ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Procesa videos de S3      ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Guarda resultados en S3   ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ M√©tricas :8001            ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß Configuraci√≥n R√°pida (AWS SQS + S3)

### 1. Crear recursos AWS necesarios

```bash
# Crear colas SQS (desde tu m√°quina local o EC2)
cd source/deployment/sqs-setup
./setup-sqs.sh us-east-1

# Anota las URLs de las colas que genera el script
# SQS_QUEUE_URL: https://sqs.us-east-1.amazonaws.com/...
# SQS_DLQ_URL: https://sqs.us-east-1.amazonaws.com/...
```

### 2. Clonar el repositorio en la instancia EC2

```bash
# Desde la instancia de performance
git clone https://github.com/TU_USUARIO/MISW-4204-desarrollo-de-software-en-la-nube.git
cd MISW-4204-desarrollo-de-software-en-la-nube/source/deployment/performance-instance
```

### 3. Configurar variables de entorno

```bash
cp .env.example .env
nano .env
```

Completa los valores principales:

```bash
# Modo de operaci√≥n (usa SQS y S3)
USE_SQS=true
USE_S3=true

# AWS SQS (URLs obtenidas del script setup-sqs.sh)
AWS_REGION=us-east-1
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-queue
SQS_DLQ_URL=https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-dlq

# AWS S3 (mismo bucket que usa el worker)
S3_BUCKET_NAME=your-bucket-name

# Credenciales AWS (desde AWS Academy > AWS Details > AWS CLI > Show)
AWS_ACCESS_KEY_ID=ASIA...
AWS_SECRET_ACCESS_KEY=...
AWS_SESSION_TOKEN=...

# API del backend (para JMeter)
API_BASE_URL=http://3.XXX.XXX.XXX

# Prometheus targets
PROMETHEUS_BACKEND_TARGET=3.XXX.XXX.XXX:8000
PROMETHEUS_WORKER_TARGET=3.YYY.YYY.YYY:8001
```

### 4. Configurar Prometheus

```bash
# El script setup-ssh-tunnel.sh ahora configura prometheus.yml autom√°ticamente
chmod +x setup-ssh-tunnel.sh
./setup-ssh-tunnel.sh
```

**Nota**: Aunque el script se llama `setup-ssh-tunnel.sh`, ahora tambi√©n configura `prometheus.yml` con las IPs del `.env`. El t√∫nel SSH solo se crea si `USE_SQS=false`.

### 5. Levantar servicios

```bash
docker-compose up -d
```

### 6. Verificar

```bash
# Ver servicios
docker ps

# Verificar conexi√≥n a SQS
docker exec producer python -c "import boto3; print(boto3.client('sqs', region_name='us-east-1').list_queues())"

# Verificar acceso a S3
docker exec producer python -c "import boto3; print(boto3.client('s3').list_buckets())"

# Acceder a Grafana
http://<PERFORMANCE_IP>:3000
Usuario: admin / Password: admin
```

## üìù Ejecuci√≥n de Pruebas

### Pruebas de API con JMeter

```bash
# Smoke test
docker exec jmeter /bin/bash -c "jmeter -n -t /scripts/smoke_test.jmx -l /scripts/smoke_results.jtl"

# Ramp-up test (100 usuarios)
docker exec jmeter /bin/bash -c "jmeter -n -t /scripts/ramp_up_test.jmx -l /scripts/ramp_up_100_users_results.jtl -Jusers=100"

# Sustained test (116 usuarios)
docker exec jmeter /bin/bash -c "jmeter -n -t /scripts/sustained_test.jmx -l /scripts/sustained_116_users_results.jtl -Jusers=116"
```

### Pruebas de Worker con Producer (AWS SQS + S3)

```bash
# Prueba b√°sica (20 videos) - Los videos se suben a S3 y tareas a SQS
docker exec producer python producer.py --num-videos 20 --no-wait

# Prueba de saturaci√≥n (100 videos)
docker exec producer python producer.py --num-videos 100 --no-wait

# Prueba con videos grandes (100MB)
docker exec producer python producer.py --num-videos 10 --video-file ./assets/dummy_file_100mb.mp4 --no-wait

# Prueba con modo debug (ver detalles de subida a S3 y SQS)
docker exec producer python producer.py --num-videos 5 --no-wait --debug
```

### Monitorear progreso de pruebas

```bash
# Ver mensajes en la cola SQS
aws sqs get-queue-attributes \
  --queue-url <SQS_QUEUE_URL> \
  --attribute-names ApproximateNumberOfMessages ApproximateNumberOfMessagesNotVisible

# Ver archivos en S3
aws s3 ls s3://<S3_BUCKET_NAME>/original/

# Ver logs del producer
docker logs -f producer

# Ver m√©tricas en Grafana
http://<PERFORMANCE_IP>:3000
```

## üêõ Troubleshooting

Ver la secci√≥n completa de troubleshooting en [DEPLOY.md](./DEPLOY.md).

## üìö Recursos Adicionales

- [GET_STARTED.md](../GET_STARTED.md) - Gu√≠a de inicio r√°pido del proyecto
- [../../performance-testing/README.md](../../performance-testing/README.md) - Documentaci√≥n completa de performance testing
- [ARCHITECTURE.md](../ARCHITECTURE.md) - Arquitectura del sistema

---

**¬øNecesitas ayuda?** Consulta [DEPLOY.md](./DEPLOY.md) para la gu√≠a completa paso a paso.
