# ==============================================================================
# CONFIGURACIÓN DEL PRODUCER PARA PRUEBAS DE CARGA (AWS SQS + S3)
# ==============================================================================

# ------------------------------------------------------------------------------
# MODO DE OPERACIÓN: SQS/S3 (AWS) vs Redis/Local (Legacy)
# ------------------------------------------------------------------------------

# IMPORTANTE: Para AWS Academy o producción, usa SQS y S3 (true)
# Solo usa Redis/Local (false) para desarrollo local o debugging

# Usar AWS SQS como broker de mensajes (true) o Redis vía SSH tunnel (false)
USE_SQS=true

# Usar AWS S3 para almacenamiento de videos (true) o volumen local (false)
USE_S3=true

# ------------------------------------------------------------------------------
# CONFIGURACIÓN DE AWS SQS (cuando USE_SQS=true)
# ------------------------------------------------------------------------------

AWS_REGION=us-east-1

# URLs de las colas SQS
# Obtén estas URLs ejecutando el script: ../../deployment/sqs-setup/setup-sqs.sh
# Ejemplo: https://sqs.us-east-1.amazonaws.com/ACCOUNT_ID/anb-video-processing-queue
SQS_QUEUE_URL=
SQS_DLQ_URL=

# ------------------------------------------------------------------------------
# CONFIGURACIÓN DE AWS S3 (cuando USE_S3=true)
# ------------------------------------------------------------------------------

# Nombre del bucket S3 para almacenamiento de videos
# Debe ser el mismo bucket que usa el worker para procesar videos
S3_BUCKET_NAME=

# ------------------------------------------------------------------------------
# CREDENCIALES DE AWS
# ------------------------------------------------------------------------------

# Para AWS Academy: Copia estas credenciales desde AWS Details > AWS CLI > Show
# Para EC2 con IAM Role: Puedes dejar estos campos vacíos

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=

# ------------------------------------------------------------------------------
# CONFIGURACIÓN LEGACY: REDIS + SSH TUNNEL (cuando USE_SQS=false)
# ------------------------------------------------------------------------------

# Solo necesitas configurar esto si USE_SQS=false (modo legacy)
# IP pública del backend de tu compañero
BACKEND_PUBLIC_IP=

# Usuario SSH del backend
BACKEND_SSH_USER=ubuntu

# Ruta a la clave SSH del backend (dentro de la instancia de performance)
BACKEND_SSH_KEY=/home/ubuntu/backend-key.pem

# URL de Redis (a través de túnel SSH)
REDIS_URL=redis://localhost:6379/0

# ------------------------------------------------------------------------------
# CONFIGURACIÓN DE LA API (para JMeter y setup JWT)
# ------------------------------------------------------------------------------

# URL base de la API del backend
# Para AWS: usa la IP pública o el DNS del Application Load Balancer
# Ejemplo: http://3.XXX.XXX.XXX o http://your-alb-dns.us-east-1.elb.amazonaws.com
API_BASE_URL=

# Usuario de prueba para JMeter (será creado automáticamente si no existe)
TEST_USER_EMAIL=performance_test@example.com
TEST_USER_PASSWORD=PerformanceTest123!

# ------------------------------------------------------------------------------
# CONFIGURACIÓN DE PROMETHEUS (Scraping de Métricas)
# ------------------------------------------------------------------------------

# IP pública del backend para scraping de métricas (puerto 8000)
# Ejemplo: 3.XXX.XXX.XXX:8000
PROMETHEUS_BACKEND_TARGET=

# IP pública del worker para scraping de métricas (puerto 8001)
# Ejemplo: 3.YYY.YYY.YYY:8001
PROMETHEUS_WORKER_TARGET=

# ------------------------------------------------------------------------------
# CONFIGURACIÓN DE GRAFANA
# ------------------------------------------------------------------------------

GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin

# ==============================================================================
# GUÍA DE CONFIGURACIÓN RÁPIDA
# ==============================================================================

# PASO 1: Copiar este archivo
#   cp .env.example .env
#   nano .env

# PASO 2: Configurar AWS SQS y S3
#   a) Ejecuta el script de setup de SQS:
#      cd ../../deployment/sqs-setup
#      ./setup-sqs.sh us-east-1
#
#   b) Copia las URLs de SQS que genera el script y pégalas arriba
#
#   c) Configura el bucket S3 (debe ser el mismo que usa el worker):
#      S3_BUCKET_NAME=your-bucket-name

# PASO 3: Configurar credenciales de AWS
#   Para AWS Academy:
#   a) Ve a AWS Details > AWS CLI > Show
#   b) Copia las credenciales (Access Key ID, Secret Access Key, Session Token)
#   c) Pégalas en las variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN
#
#   Para EC2 con IAM Role:
#   - No necesitas configurar credenciales, la instancia las obtiene automáticamente

# PASO 4: Configurar API y Prometheus
#   - API_BASE_URL: URL del backend (ALB o IP pública)
#   - PROMETHEUS_BACKEND_TARGET: IP:puerto del backend para métricas
#   - PROMETHEUS_WORKER_TARGET: IP:puerto del worker para métricas

# PASO 5: Actualizar prometheus.yml con las IPs
#   ./setup-ssh-tunnel.sh  # Este script ahora también configura prometheus.yml

# PASO 6: Levantar servicios
#   docker-compose up -d

# ==============================================================================
# NOTAS DE SEGURIDAD
# ==============================================================================

# 1. NUNCA subas el archivo .env a Git (está en .gitignore)
# 2. Las credenciales de AWS Academy expiran cada 4 horas
# 3. Renueva las credenciales ejecutando:
#    - Obtén nuevas credenciales de AWS Academy
#    - Actualiza .env con las nuevas credenciales
#    - Reinicia el producer: docker-compose restart producer
