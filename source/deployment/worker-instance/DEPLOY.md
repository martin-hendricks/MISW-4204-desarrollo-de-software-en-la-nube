# Gu√≠a de Despliegue - Instancia Worker

## Resumen
Esta instancia EC2 contiene:
- ‚úÖ Celery Worker (Procesamiento de videos con FFmpeg) - 2 workers
- ‚úÖ Health Check API (FastAPI) - Puerto 8001
- ‚úÖ Integraci√≥n con AWS SQS (Message Broker)
- ‚úÖ Integraci√≥n con AWS S3 (Almacenamiento de archivos)

---

## Requisitos Previos

### 1. Instancia EC2 configurada
- ‚úÖ Ubuntu Server 22.04 LTS
- ‚úÖ Tipo: t2.medium o superior (recomendado t2.large para procesamiento)
- ‚úÖ Docker y Docker Compose instalados
- ‚úÖ Security Group configurado (ver abajo)

### 2. Servicios externos funcionando
- ‚úÖ RDS PostgreSQL creado y accesible
- ‚úÖ AWS SQS colas creadas (main queue y DLQ) - las mismas que usa el Backend
- ‚úÖ AWS S3 bucket creado - el mismo que usa el Backend
- ‚úÖ Backend desplegado y funcionando

### 3. Informaci√≥n que necesitas tener a mano
- IP p√∫blica de la instancia Backend (para BASE_PATH)
- Endpoint de RDS PostgreSQL
- Usuario y contrase√±a de RDS
- SQS Queue URL y DLQ URL (las mismas que el Backend)
- S3 Bucket Name (el mismo que el Backend)
- AWS credentials (las mismas que el Backend)

### 4. Assets de video
- Logo ANB (anb_logo.png)
- Video intro (intro.mp4) - m√°ximo 2.5 segundos
- Video outro (outro.mp4) - m√°ximo 2.5 segundos

---

## Security Group - Worker Instance

### Inbound Rules

| Type | Protocol | Port | Source | Description |
|------|----------|------|--------|-------------|
| SSH | TCP | 22 | Your IP | Administraci√≥n SSH |
| Custom TCP | TCP | 8001 | Your IP | Health API (debug) |
| Custom TCP | TCP | 8001 | Backend SG | Health checks desde Backend |

### Outbound Rules
- All traffic (default)

**IMPORTANTE:** El Worker necesita poder conectarse a:
- RDS PostgreSQL (puerto 5432)
- AWS SQS (puerto 443 - HTTPS)
- AWS S3 (puerto 443 - HTTPS)

---

## ‚ö†Ô∏è IMPORTANTE: Configuraci√≥n Previa al Despliegue

**Antes de ejecutar `docker-compose up`**, debes configurar el archivo `.env` con los valores correctos:

### üìù Archivo que DEBES editar:

| Archivo | Qu√© configurar |
|---------|----------------|
| **`.env`** | `DATABASE_URL` (RDS endpoint - el mismo que el Backend) |
| **`.env`** | `BASE_PATH` (URL p√∫blica del Backend - IP P√öBLICA del Backend) |
| **`.env`** | `SQS_QUEUE_URL` y `SQS_DLQ_URL` (las mismas que el Backend) |
| **`.env`** | `S3_BUCKET_NAME` y credenciales AWS (las mismas que el Backend) |

### üîÑ ¬øNecesitas recrear contenedores despu√©s de cambiar configuraci√≥n?

**S√ç, debes recrear** si cambias cualquiera de estos valores despu√©s del primer despliegue:

```bash
# Detener y eliminar contenedores actuales
docker-compose down

# Editar archivos de configuraci√≥n
nano .env

# Reconstruir y levantar con nueva configuraci√≥n
docker-compose up -d --build
```

**NO necesitas recrear** si solo cambias:
- Logs
- Concurrencia de Celery (`CELERY_CONCURRENCY`)
- Variables de configuraci√≥n que no afectan conectividad

**NOTA:** Si cambias `CELERY_CONCURRENCY`, solo necesitas reiniciar:
```bash
docker-compose restart worker
```

---

## Pasos de Despliegue

### Paso 1: Conectarse a la instancia

```bash
ssh -i "your-key.pem" ubuntu@<WORKER_PUBLIC_IP>
```

### Paso 2: Clonar/Copiar los archivos del proyecto

```bash
# Crear directorio de trabajo
mkdir -p ~/anb-worker
cd ~/anb-worker

# Opci√≥n A: Clonar repositorio (si est√° en GitHub)
git clone <your-repo-url> .
cd source/deployment/worker-instance

# Opci√≥n B: Copiar archivos manualmente usando SCP desde tu m√°quina local
# Desde tu m√°quina local:
# scp -i "your-key.pem" -r ./source/deployment/worker-instance ubuntu@<WORKER_PUBLIC_IP>:~/anb-worker/
# scp -i "your-key.pem" -r ./source/worker ubuntu@<WORKER_PUBLIC_IP>:~/anb-worker/
```

### Paso 3: Preparar carpeta de assets

```bash
cd ~/anb-worker/deployment/worker-instance

# Crear carpeta de assets
mkdir -p assets

# Copiar assets desde tu m√°quina local
# Desde tu m√°quina local:
# scp -i "your-key.pem" anb_logo.png ubuntu@<WORKER_PUBLIC_IP>:~/anb-worker/deployment/worker-instance/assets/
# scp -i "your-key.pem" intro.mp4 ubuntu@<WORKER_PUBLIC_IP>:~/anb-worker/deployment/worker-instance/assets/
# scp -i "your-key.pem" outro.mp4 ubuntu@<WORKER_PUBLIC_IP>:~/anb-worker/deployment/worker-instance/assets/

# Verificar que los archivos est√°n presentes
ls -lh assets/
```

**Requisitos de los assets:**
- `anb_logo.png`: Logo ANB en formato PNG con transparencia (recomendado 200x200px)
- `intro.mp4`: Video intro, m√°ximo 2.5 segundos, 1280x720
- `outro.mp4`: Video outro, m√°ximo 2.5 segundos, 1280x720

### Paso 4: Configurar variables de entorno

```bash
cd ~/anb-worker/deployment/worker-instance

# Copiar archivo de ejemplo
cp .env.example .env

# Editar con tus valores reales
nano .env
```

**Variables que DEBES cambiar:**

```bash
# RDS Database (mismo que Backend)
DATABASE_URL=postgresql://admin:YourPassword@anb-db.xxx.us-east-1.rds.amazonaws.com:5432/anbdb

# AWS SQS (mismas URLs que Backend)
USE_SQS=true
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789/anb-video-processing
SQS_DLQ_URL=https://sqs.us-east-1.amazonaws.com/123456789/anb-video-processing-dlq

# AWS S3 (mismo bucket y credenciales que Backend)
STORAGE_TYPE=s3
S3_BUCKET_NAME=anb-videos-bucket
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1

# Base Path (IP P√öBLICA del Backend)
BASE_PATH=http://<BACKEND_PUBLIC_IP>/api/videos
```

### Paso 5: Configurar Almacenamiento S3

**Pre-requisito:** El bucket S3 debe estar creado y configurado (mismo que el Backend)

```bash
# Dar permisos de ejecuci√≥n
chmod +x setup-s3.sh

# Ejecutar el script
./setup-s3.sh
```

El script:
- ‚úÖ Valida las credenciales AWS (deben ser las **mismas** que en Backend)
- ‚úÖ Instala AWS CLI
- ‚úÖ Configura las credenciales (incluyendo session_token si existe)
- ‚úÖ Verifica acceso al bucket S3

**Verificar acceso a S3:**

```bash
aws s3 ls s3://anb-videos-bucket-2025-team-2/
```

Deber√≠as ver el mismo contenido que desde el Backend:

```
                           PRE original/
                           PRE processed/
```

---

### Paso 6: Construir y levantar el servicio

```bash
cd ~/anb-worker/deployment/worker-instance

# Construir la imagen
docker-compose build

# Levantar el servicio en segundo plano
docker-compose up -d

# Ver logs
docker-compose logs -f
```

### Paso 7: Verificar que el worker est√° corriendo

```bash
# Ver estado del contenedor
docker-compose ps

# Deber√≠as ver:
# NAME          IMAGE                     STATUS
# anb-worker    worker-instance-worker    Up (healthy)

# Ver logs del worker
docker-compose logs -f worker

# Deber√≠as ver l√≠neas como:
# [2025-01-15 10:30:00] [INFO] celery.worker.strategy: Starting Celery worker
# [2025-01-15 10:30:01] [INFO] Connected to SQS
# [2025-01-15 10:30:02] [INFO] Ready to accept tasks
```

### Paso 8: Verificar health check

```bash
# Desde la instancia Worker
curl http://localhost:8001/health

# Deber√≠as ver algo como:
# {
#   "status": "healthy",
#   "celery_status": "running",
#   "sqs_connection": "ok",
#   "database_connection": "ok",
#   "s3_access": "ok"
# }
```

### Paso 9: Verificar tareas de Celery

```bash
# Ver workers activos
docker exec -it anb-worker celery -A celery_app inspect active

# Ver estad√≠sticas
docker exec -it anb-worker celery -A celery_app inspect stats
```

Deber√≠as ver:
- 2 workers activos (configurable con CELERY_CONCURRENCY)
- Queues: `video_processing` y `dlq`
- Estado: Online

---

## Verificaci√≥n de Funcionamiento Completo

### Prueba End-to-End

1. **Subir un video desde el Backend:**

```bash
# Desde tu m√°quina local
curl -X POST http://<BACKEND_PUBLIC_IP>/api/videos/upload \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -F "file=@test_video.mp4"
```

2. **Ver el progreso en los logs:**

```bash
# En la instancia Worker
docker-compose logs -f worker | grep process_video
```

Deber√≠as ver la tarea `process_video` progresando:
- `PENDING` ‚Üí `STARTED` ‚Üí `SUCCESS`

3. **Verificar en S3:**

```bash
# Verificar archivos en S3
aws s3 ls s3://anb-videos-bucket/original/
aws s3 ls s3://anb-videos-bucket/processed/

# Deber√≠as ver el video original y el procesado
```

4. **Consultar estado en la API:**

```bash
# Verificar estado del video
curl -X GET http://<BACKEND_PUBLIC_IP>/api/videos \
  -H "Authorization: Bearer <JWT_TOKEN>"

# El video deber√≠a tener status: "processed"
```

---

## Comandos √ötiles

### Ver logs

```bash
# Logs del worker
docker-compose logs -f worker

# √öltimas 100 l√≠neas
docker-compose logs --tail=100 worker

# Filtrar por palabra clave
docker-compose logs -f worker | grep ERROR
```

### Reiniciar worker

```bash
# Reiniciar contenedor
docker-compose restart worker

# Reiniciar solo Celery (dentro del contenedor)
docker-compose exec worker pkill -HUP celery
```

### Ver estado de Celery

```bash
# Entrar al contenedor
docker exec -it anb-worker bash

# Ver workers activos
celery -A celery_app inspect active

# Ver tareas en cola
celery -A celery_app inspect reserved

# Ver estad√≠sticas
celery -A celery_app inspect stats

# Salir
exit
```

### Monitorear procesamiento en tiempo real

```bash
# Ver logs con timestamp
docker-compose logs -f --timestamps worker

# Monitorear archivos procesados en S3
watch -n 5 'aws s3 ls s3://anb-videos-bucket/processed/ | tail -n 10'
```

---

## Troubleshooting

### Error: "Cannot connect to SQS"

```bash
# Verificar que las colas existen
aws sqs list-queues

# Verificar URL de la cola
aws sqs get-queue-attributes --queue-url <YOUR_QUEUE_URL>

# Verificar credenciales
cat .env | grep SQS_QUEUE_URL
cat .env | grep AWS_

# Ver logs del worker
docker-compose logs worker
```

### Error: "Cannot connect to S3"

```bash
# Verificar acceso al bucket
aws s3 ls s3://<YOUR_BUCKET_NAME>

# Verificar credenciales
cat .env | grep S3_BUCKET_NAME
cat .env | grep AWS_

# Ver logs del worker
docker-compose logs worker
```

### Error: "Cannot connect to database"

```bash
# Verificar que RDS es alcanzable
telnet <RDS_ENDPOINT> 5432

# Verificar credenciales en .env
cat .env | grep DATABASE_URL
```

### Error: "FFmpeg not found"

```bash
# Verificar que FFmpeg est√° instalado en el contenedor
docker exec -it anb-worker ffmpeg -version

# Si no est√°, rebuild la imagen
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### Error: "Logo/Intro/Outro not found"

```bash
# Verificar que los assets est√°n montados en el contenedor
docker exec -it anb-worker ls -la /app/assets/

# Deber√≠as ver:
# anb_logo.png
# intro.mp4
# outro.mp4

# Si no est√°n, verifica la carpeta en el host
ls -la ~/anb-worker/deployment/worker-instance/assets/
```

### Worker no procesa tareas

```bash
# Ver logs detallados
docker-compose logs -f worker

# Verificar conexi√≥n a SQS
docker exec -it anb-worker python -c "
from celery_app import app
app.connection().connect()
print('SQS OK')
"

# Verificar que las colas est√°n configuradas
docker exec -it anb-worker celery -A celery_app inspect active_queues
```

### Tareas quedan en estado PENDING

```bash
# Ver tareas activas
docker exec -it anb-worker celery -A celery_app inspect active

# Verificar routing de tareas
docker exec -it anb-worker celery -A celery_app inspect registered

# Reiniciar worker
docker-compose restart worker
```

### Procesamiento muy lento

```bash
# Ver recursos del sistema
htop  # o: top

# Ver estad√≠sticas de Docker
docker stats anb-worker

# Considerar:
# 1. Aumentar tipo de instancia (t2.large ‚Üí t2.xlarge)
# 2. Reducir concurrency en .env: CELERY_CONCURRENCY=2
# 3. Escalar horizontalmente (crear m√°s instancias Worker)
```

---

## Escalamiento Horizontal

Para agregar m√°s workers (procesar m√°s videos en paralelo):

### Opci√≥n 1: Aumentar concurrency en esta instancia

```bash
# Editar .env
nano .env

# Cambiar:
CELERY_CONCURRENCY=8  # de 4 a 8

# Reiniciar
docker-compose restart worker
```

### Opci√≥n 2: Crear m√°s instancias Worker id√©nticas

1. Crear nueva instancia EC2 id√©ntica
2. Repetir todos los pasos de despliegue
3. Ambas instancias consumir√°n de la misma cola SQS
4. Load balancing autom√°tico por SQS

---

## Monitoreo Continuo

### Health Check API

```bash
# Verificar salud cada 30 segundos
watch -n 30 'curl -s http://localhost:8001/health | jq'
```


### Alertas (opcional)

Configurar alertas cuando:
- Worker deja de procesar tareas
- Tareas fallan repetidamente
- Errores de acceso a S3 o SQS

---

## Backup y Mantenimiento

### Logs

```bash
# Exportar logs para an√°lisis
docker-compose logs worker > worker-logs-$(date +%F).log
```

### Limpiar contenedores viejos

```bash
# Limpiar im√°genes sin usar
docker system prune -a

# Ver espacio usado
docker system df
```

### Actualizar c√≥digo

```bash
# Pull cambios
git pull origin main

# Rebuild y redeploy
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

---

## Siguientes Pasos

Una vez que el Worker est√© funcionando:

1. ‚úÖ Worker desplegado y procesando tareas
2. ‚è≠Ô∏è Probar flujo completo end-to-end
3. ‚è≠Ô∏è Configurar monitoreo y alertas
4. ‚è≠Ô∏è Optimizar performance seg√∫n carga
5. ‚è≠Ô∏è Documentar m√©tricas de procesamiento

---

## Comandos R√°pidos de Referencia

```bash
# Configurar S3
./setup-s3.sh

# Levantar worker
docker-compose up -d

# Ver logs
docker-compose logs -f worker

# Verificar salud
curl http://localhost:8001/health

# Ver tareas activas
docker exec -it anb-worker celery -A celery_app inspect active

# Monitorear archivos procesados en S3
watch -n 5 'aws s3 ls s3://anb-videos-bucket/processed/ | tail -n 10'

# Reiniciar
docker-compose restart worker

# Detener
docker-compose down
```
